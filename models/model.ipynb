{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        userId  movieId  rating   timestamp\n0            1        1     4.0   964982703\n1            1        3     4.0   964981247\n2            1        6     4.0   964982224\n3            1       47     5.0   964983815\n4            1       50     5.0   964982931\n...        ...      ...     ...         ...\n100831     610   166534     4.0  1493848402\n100832     610   168248     5.0  1493850091\n100833     610   168250     5.0  1494273047\n100834     610   168252     5.0  1493846352\n100835     610   170875     3.0  1493846415\n\n[100836 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100831</th>\n      <td>610</td>\n      <td>166534</td>\n      <td>4.0</td>\n      <td>1493848402</td>\n    </tr>\n    <tr>\n      <th>100832</th>\n      <td>610</td>\n      <td>168248</td>\n      <td>5.0</td>\n      <td>1493850091</td>\n    </tr>\n    <tr>\n      <th>100833</th>\n      <td>610</td>\n      <td>168250</td>\n      <td>5.0</td>\n      <td>1494273047</td>\n    </tr>\n    <tr>\n      <th>100834</th>\n      <td>610</td>\n      <td>168252</td>\n      <td>5.0</td>\n      <td>1493846352</td>\n    </tr>\n    <tr>\n      <th>100835</th>\n      <td>610</td>\n      <td>170875</td>\n      <td>3.0</td>\n      <td>1493846415</td>\n    </tr>\n  </tbody>\n</table>\n<p>100836 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../data/ratings.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9724 610\n"
    }
   ],
   "source": [
    "arr = np.array(dataset, dtype='int')\n",
    "\n",
    "nb_users = int(max(arr[:, 0]))\n",
    "nb_movies = len(dataset.movieId.unique())\n",
    "print(nb_movies, nb_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "movieId  1       2       3       4       5       6       7       8       \\\nuserId                                                                    \n1           4.0     0.0     4.0     0.0     0.0     4.0     0.0       0   \n2           0.0     0.0     0.0     0.0     0.0     0.0     0.0       0   \n3           0.0     0.0     0.0     0.0     0.0     0.0     0.0       0   \n4           0.0     0.0     0.0     0.0     0.0     0.0     0.0       0   \n5           4.0     0.0     0.0     0.0     0.0     0.0     0.0       0   \n...         ...     ...     ...     ...     ...     ...     ...     ...   \n606         2.5     0.0     0.0     0.0     0.0     0.0     2.5       0   \n607         4.0     0.0     0.0     0.0     0.0     0.0     0.0       0   \n608         2.5     2.0     2.0     0.0     0.0     0.0     0.0       0   \n609         3.0     0.0     0.0     0.0     0.0     0.0     0.0       0   \n610         5.0     0.0     0.0     0.0     0.0     5.0     0.0       0   \n\nmovieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\nuserId                   ...                                                   \n1           0.0     0.0  ...     0.0       0       0       0     0.0       0   \n2           0.0     0.0  ...     0.0       0       0       0     0.0       0   \n3           0.0     0.0  ...     0.0       0       0       0     0.0       0   \n4           0.0     0.0  ...     0.0       0       0       0     0.0       0   \n5           0.0     0.0  ...     0.0       0       0       0     0.0       0   \n...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n606         0.0     0.0  ...     0.0       0       0       0     0.0       0   \n607         0.0     0.0  ...     0.0       0       0       0     0.0       0   \n608         0.0     4.0  ...     0.0       0       0       0     0.0       0   \n609         0.0     4.0  ...     0.0       0       0       0     0.0       0   \n610         0.0     0.0  ...     0.0       0       0       0     0.0       0   \n\nmovieId  193583  193585  193587  193609  \nuserId                                   \n1           0.0     0.0     0.0       0  \n2           0.0     0.0     0.0       0  \n3           0.0     0.0     0.0       0  \n4           0.0     0.0     0.0       0  \n5           0.0     0.0     0.0       0  \n...         ...     ...     ...     ...  \n606         0.0     0.0     0.0       0  \n607         0.0     0.0     0.0       0  \n608         0.0     0.0     0.0       0  \n609         0.0     0.0     0.0       0  \n610         0.0     0.0     0.0       0  \n\n[610 rows x 9724 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>movieId</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>193565</th>\n      <th>193567</th>\n      <th>193571</th>\n      <th>193573</th>\n      <th>193579</th>\n      <th>193581</th>\n      <th>193583</th>\n      <th>193585</th>\n      <th>193587</th>\n      <th>193609</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>610 rows × 9724 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "pivot_table = dataset.pivot_table(index = [\"userId\"], columns = [\"movieId\"], values = \"rating\", fill_value=0)\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(610, 9724)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data = pivot_table.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 500)\n",
    "        self.fc2 = nn.Linear(500, 20)\n",
    "        self.fc3 = nn.Linear(20, 8)\n",
    "        self.fc4 = nn.Linear(8, 20)\n",
    "        self.fc5 = nn.Linear(20, 500)\n",
    "        self.fc6 = nn.Linear(500, nb_movies)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.activation(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "running on the gpu\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SAE(\n  (fc1): Linear(in_features=9724, out_features=500, bias=True)\n  (fc2): Linear(in_features=500, out_features=20, bias=True)\n  (fc3): Linear(in_features=20, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=20, bias=True)\n  (fc5): Linear(in_features=20, out_features=500, bias=True)\n  (fc6): Linear(in_features=500, out_features=9724, bias=True)\n  (activation): Tanh()\n)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the gpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the cpu\")\n",
    "\n",
    "sae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1  loss: tensor(3.7188)\nepoch: 2  loss: tensor(2.5533)\nepoch: 3  loss: tensor(1.5697)\nepoch: 4  loss: tensor(1.4570)\nepoch: 5  loss: tensor(1.3441)\nepoch: 6  loss: tensor(1.2251)\nepoch: 7  loss: tensor(1.1928)\nepoch: 8  loss: tensor(1.1552)\nepoch: 9  loss: tensor(1.1332)\nepoch: 10  loss: tensor(1.1135)\nepoch: 11  loss: tensor(1.0947)\nepoch: 12  loss: tensor(1.0828)\nepoch: 13  loss: tensor(1.0622)\nepoch: 14  loss: tensor(1.0539)\nepoch: 15  loss: tensor(1.0430)\nepoch: 16  loss: tensor(1.0308)\nepoch: 17  loss: tensor(1.0169)\nepoch: 18  loss: tensor(1.0111)\nepoch: 19  loss: tensor(1.0091)\nepoch: 20  loss: tensor(1.0054)\nepoch: 21  loss: tensor(0.9901)\nepoch: 22  loss: tensor(0.9902)\nepoch: 23  loss: tensor(0.9853)\nepoch: 24  loss: tensor(0.9765)\nepoch: 25  loss: tensor(1.0159)\nepoch: 26  loss: tensor(1.3299)\nepoch: 27  loss: tensor(1.2937)\nepoch: 28  loss: tensor(1.2490)\nepoch: 29  loss: tensor(1.1967)\nepoch: 30  loss: tensor(1.1760)\nepoch: 31  loss: tensor(1.1521)\nepoch: 32  loss: tensor(1.1366)\nepoch: 33  loss: tensor(1.1230)\nepoch: 34  loss: tensor(1.1174)\nepoch: 35  loss: tensor(1.1093)\nepoch: 36  loss: tensor(1.1073)\nepoch: 37  loss: tensor(1.0937)\nepoch: 38  loss: tensor(1.0824)\nepoch: 39  loss: tensor(1.0729)\nepoch: 40  loss: tensor(1.0591)\nepoch: 41  loss: tensor(1.0741)\nepoch: 42  loss: tensor(1.0661)\nepoch: 43  loss: tensor(1.0597)\nepoch: 44  loss: tensor(1.0441)\nepoch: 45  loss: tensor(1.0449)\nepoch: 46  loss: tensor(1.0327)\nepoch: 47  loss: tensor(1.0167)\nepoch: 48  loss: tensor(1.0316)\nepoch: 49  loss: tensor(1.0268)\nepoch: 50  loss: tensor(1.0162)\nepoch: 51  loss: tensor(1.0255)\nepoch: 52  loss: tensor(1.0242)\nepoch: 53  loss: tensor(1.0027)\nepoch: 54  loss: tensor(0.9957)\nepoch: 55  loss: tensor(0.9956)\nepoch: 56  loss: tensor(1.0073)\nepoch: 57  loss: tensor(0.9962)\nepoch: 58  loss: tensor(1.0008)\nepoch: 59  loss: tensor(0.9999)\nepoch: 60  loss: tensor(0.9832)\nepoch: 61  loss: tensor(0.9841)\nepoch: 62  loss: tensor(0.9770)\nepoch: 63  loss: tensor(0.9732)\nepoch: 64  loss: tensor(0.9844)\nepoch: 65  loss: tensor(0.9684)\nepoch: 66  loss: tensor(0.9717)\nepoch: 67  loss: tensor(0.9723)\nepoch: 68  loss: tensor(0.9713)\nepoch: 69  loss: tensor(0.9571)\nepoch: 70  loss: tensor(0.9702)\nepoch: 71  loss: tensor(0.9522)\nepoch: 72  loss: tensor(0.9535)\nepoch: 73  loss: tensor(0.9438)\nepoch: 74  loss: tensor(0.9567)\nepoch: 75  loss: tensor(0.9454)\nepoch: 76  loss: tensor(0.9480)\nepoch: 77  loss: tensor(0.9501)\nepoch: 78  loss: tensor(0.9302)\nepoch: 79  loss: tensor(0.9375)\nepoch: 80  loss: tensor(0.9421)\nepoch: 81  loss: tensor(0.9232)\nepoch: 82  loss: tensor(0.9140)\nepoch: 83  loss: tensor(0.9434)\nepoch: 84  loss: tensor(0.9361)\nepoch: 85  loss: tensor(0.9109)\nepoch: 86  loss: tensor(0.9211)\nepoch: 87  loss: tensor(0.9247)\nepoch: 88  loss: tensor(0.9096)\nepoch: 89  loss: tensor(0.9163)\nepoch: 90  loss: tensor(0.9034)\nepoch: 91  loss: tensor(0.9049)\nepoch: 92  loss: tensor(0.9062)\nepoch: 93  loss: tensor(0.9194)\nepoch: 94  loss: tensor(0.9178)\nepoch: 95  loss: tensor(0.9197)\nepoch: 96  loss: tensor(0.9044)\nepoch: 97  loss: tensor(0.8975)\nepoch: 98  loss: tensor(0.8902)\nepoch: 99  loss: tensor(0.8890)\nepoch: 100  loss: tensor(0.9026)\nepoch: 101  loss: tensor(0.9033)\nepoch: 102  loss: tensor(0.8965)\nepoch: 103  loss: tensor(0.8895)\nepoch: 104  loss: tensor(0.8967)\nepoch: 105  loss: tensor(0.9100)\nepoch: 106  loss: tensor(0.8970)\nepoch: 107  loss: tensor(0.8974)\nepoch: 108  loss: tensor(0.8939)\nepoch: 109  loss: tensor(0.8947)\nepoch: 110  loss: tensor(0.8943)\nepoch: 111  loss: tensor(0.8895)\nepoch: 112  loss: tensor(0.8844)\nepoch: 113  loss: tensor(0.8726)\nepoch: 114  loss: tensor(0.8743)\nepoch: 115  loss: tensor(0.8703)\nepoch: 116  loss: tensor(0.8737)\nepoch: 117  loss: tensor(0.8875)\nepoch: 118  loss: tensor(0.8727)\nepoch: 119  loss: tensor(0.8757)\nepoch: 120  loss: tensor(0.8646)\nepoch: 121  loss: tensor(0.8790)\nepoch: 122  loss: tensor(0.9056)\nepoch: 123  loss: tensor(0.8822)\nepoch: 124  loss: tensor(0.8689)\nepoch: 125  loss: tensor(0.8733)\nepoch: 126  loss: tensor(0.8719)\nepoch: 127  loss: tensor(0.8717)\nepoch: 128  loss: tensor(0.8743)\nepoch: 129  loss: tensor(0.8591)\nepoch: 130  loss: tensor(0.8690)\nepoch: 131  loss: tensor(0.8690)\nepoch: 132  loss: tensor(0.8677)\nepoch: 133  loss: tensor(0.8613)\nepoch: 134  loss: tensor(0.8949)\nepoch: 135  loss: tensor(0.8852)\nepoch: 136  loss: tensor(0.9191)\nepoch: 137  loss: tensor(0.8916)\nepoch: 138  loss: tensor(0.8804)\nepoch: 139  loss: tensor(0.8712)\nepoch: 140  loss: tensor(0.8847)\nepoch: 141  loss: tensor(0.8747)\nepoch: 142  loss: tensor(0.8734)\nepoch: 143  loss: tensor(0.8646)\nepoch: 144  loss: tensor(0.8580)\nepoch: 145  loss: tensor(0.8586)\nepoch: 146  loss: tensor(0.8623)\nepoch: 147  loss: tensor(0.8939)\nepoch: 148  loss: tensor(0.8770)\nepoch: 149  loss: tensor(0.8517)\nepoch: 150  loss: tensor(0.8685)\nepoch: 151  loss: tensor(0.8562)\nepoch: 152  loss: tensor(0.8562)\nepoch: 153  loss: tensor(0.8478)\nepoch: 154  loss: tensor(0.8664)\nepoch: 155  loss: tensor(0.8500)\nepoch: 156  loss: tensor(0.8593)\nepoch: 157  loss: tensor(0.8536)\nepoch: 158  loss: tensor(0.8407)\nepoch: 159  loss: tensor(0.8601)\nepoch: 160  loss: tensor(0.8643)\nepoch: 161  loss: tensor(0.8489)\nepoch: 162  loss: tensor(0.8505)\nepoch: 163  loss: tensor(0.8497)\nepoch: 164  loss: tensor(0.8530)\nepoch: 165  loss: tensor(0.8473)\nepoch: 166  loss: tensor(0.8473)\nepoch: 167  loss: tensor(0.8423)\nepoch: 168  loss: tensor(0.8370)\nepoch: 169  loss: tensor(0.8366)\nepoch: 170  loss: tensor(0.8315)\nepoch: 171  loss: tensor(0.8314)\nepoch: 172  loss: tensor(0.8377)\nepoch: 173  loss: tensor(0.8275)\nepoch: 174  loss: tensor(0.8205)\nepoch: 175  loss: tensor(0.8206)\nepoch: 176  loss: tensor(0.8210)\nepoch: 177  loss: tensor(0.8518)\nepoch: 178  loss: tensor(0.8459)\nepoch: 179  loss: tensor(0.8495)\nepoch: 180  loss: tensor(0.8432)\nepoch: 181  loss: tensor(0.8272)\nepoch: 182  loss: tensor(0.8301)\nepoch: 183  loss: tensor(0.8402)\nepoch: 184  loss: tensor(0.8333)\nepoch: 185  loss: tensor(0.8308)\nepoch: 186  loss: tensor(0.8204)\nepoch: 187  loss: tensor(0.8280)\nepoch: 188  loss: tensor(0.8172)\nepoch: 189  loss: tensor(0.8098)\nepoch: 190  loss: tensor(0.8140)\nepoch: 191  loss: tensor(0.8281)\nepoch: 192  loss: tensor(0.8208)\nepoch: 193  loss: tensor(0.8323)\nepoch: 194  loss: tensor(0.8184)\nepoch: 195  loss: tensor(0.8217)\nepoch: 196  loss: tensor(0.8288)\nepoch: 197  loss: tensor(0.8210)\nepoch: 198  loss: tensor(0.8137)\nepoch: 199  loss: tensor(0.8185)\nepoch: 200  loss: tensor(0.8418)\n"
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for user_id in range(nb_users):\n",
    "        input = Variable(data[user_id]).unsqueeze(0).to(device)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            target = target.to(device)\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data.cpu() * mean_corrector)\n",
    "            s += 1\n",
    "            optimizer.step()\n",
    "    print('epoch: ' + str(epoch) + '  loss: ' + str(train_loss / s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sae.state_dict(), 'new_sae_200.pt')"
   ]
  }
 ]
}